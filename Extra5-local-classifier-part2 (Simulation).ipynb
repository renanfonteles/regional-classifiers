{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><h1>Classification by local modeling</h1></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary:\n",
    "1. [Introduction](#introduction)\n",
    "\n",
    "2. [Local Ordinary Least Squares (L-OLS)](#lols)\n",
    "    \n",
    "    2.1. [Influence of the number of clusters on model accuracy](#lols-#-clusters)\n",
    "    \n",
    "3. [Local Least Squares Support Vector Machine (L-LSSVM)](#l_lssvm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Introduction <a class=\"anchor\" id=\"introduction\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classic classification by local modeling is a two-step approach for modeling:\n",
    "\n",
    "1. An unsupervised clustering algorithm is run to find regions in the dataset;\n",
    "2. For each region, a model is built with the respective data partition.\n",
    "\n",
    "For inference the procedure is similar:\n",
    "\n",
    "1. A similarity metric is used to determine the new data point region, e.g. euclidian distance from regions prototypes;\n",
    "2. The model from that specific region is used to predict the class of the new data point.\n",
    "\n",
    "There are a lot of clustering algorithms but, for the sake of simplicity, it will be used only K-means."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from devcode.utils import scale_feat, dummie2multilabel, cm2acc\n",
    "from devcode import run_simulation, run_round\n",
    "from devcode.models.lssvm import LSSVM\n",
    "from devcode.models.local_learning import LocalModel\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from load_dataset import get_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = get_datasets()\n",
    "\n",
    "base_path = \"results/simulations/\" # Folder where the simulation files will be saved\n",
    "\n",
    "# Hyper-parameters:\n",
    "n_init    = 5         # Number of independent runs\n",
    "test_size = 0.2       # Test size of 20%\n",
    "scaleType = 'min-max' # Type of feature scaling\n",
    "\n",
    "results_df = {'GOLS': {}, 'LOLS': {}}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Global model training\n",
    "\n",
    "As a baseline, we will use a global model, in this case, a global linear model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.8387096774193549\n",
      "Test accuracy:  0.9032258064516129\n",
      "\n",
      "Train accuracy: 0.842741935483871\n",
      "Test accuracy:  0.8064516129032258\n",
      "\n",
      "Train accuracy: 0.8467741935483871\n",
      "Test accuracy:  0.8548387096774194\n",
      "\n",
      "Train accuracy: 0.8508064516129032\n",
      "Test accuracy:  0.8387096774193549\n",
      "\n",
      "Train accuracy: 0.8266129032258065\n",
      "Test accuracy:  0.8709677419354839\n",
      "\n",
      "Train accuracy: 0.8145161290322581\n",
      "Test accuracy:  0.6935483870967742\n",
      "\n",
      "Train accuracy: 0.7983870967741935\n",
      "Test accuracy:  0.8225806451612904\n",
      "\n",
      "Train accuracy: 0.7741935483870968\n",
      "Test accuracy:  0.8709677419354839\n",
      "\n",
      "Train accuracy: 0.7741935483870968\n",
      "Test accuracy:  0.7580645161290323\n",
      "\n",
      "Train accuracy: 0.7741935483870968\n",
      "Test accuracy:  0.8225806451612904\n",
      "\n",
      "Train accuracy: 0.6482584784601283\n",
      "Test accuracy:  0.6401098901098901\n",
      "\n",
      "Train accuracy: 0.6287809349220899\n",
      "Test accuracy:  0.6666666666666666\n",
      "\n",
      "Train accuracy: 0.6455087076076994\n",
      "Test accuracy:  0.6172161172161172\n",
      "\n",
      "Train accuracy: 0.6402383134738772\n",
      "Test accuracy:  0.63003663003663\n",
      "\n",
      "Train accuracy: 0.6425297891842346\n",
      "Test accuracy:  0.6556776556776557\n",
      "\n",
      "Train accuracy: 0.7234188817598534\n",
      "Test accuracy:  0.7371794871794872\n",
      "\n",
      "Train accuracy: 0.7284601283226397\n",
      "Test accuracy:  0.7124542124542125\n",
      "\n",
      "Train accuracy: 0.7261686526122824\n",
      "Test accuracy:  0.7216117216117216\n",
      "\n",
      "Train accuracy: 0.7277726856095326\n",
      "Test accuracy:  0.7133699633699634\n",
      "\n",
      "Train accuracy: 0.7222731439046746\n",
      "Test accuracy:  0.7307692307692307\n",
      "\n",
      "Train accuracy: 0.7247937671860678\n",
      "Test accuracy:  0.7124542124542125\n",
      "\n",
      "Train accuracy: 0.7259395050412466\n",
      "Test accuracy:  0.7051282051282052\n",
      "\n",
      "Train accuracy: 0.7218148487626032\n",
      "Test accuracy:  0.6923076923076923\n",
      "\n",
      "Train accuracy: 0.7247937671860678\n",
      "Test accuracy:  0.7197802197802198\n",
      "\n",
      "Train accuracy: 0.7218148487626032\n",
      "Test accuracy:  0.739010989010989\n",
      "\n",
      "Train accuracy: 0.9102564102564102\n",
      "Test accuracy:  0.8717948717948718\n",
      "\n",
      "Train accuracy: 0.9038461538461539\n",
      "Test accuracy:  0.8974358974358975\n",
      "\n",
      "Train accuracy: 0.9166666666666666\n",
      "Test accuracy:  0.8205128205128205\n",
      "\n",
      "Train accuracy: 0.9102564102564102\n",
      "Test accuracy:  0.8717948717948718\n",
      "\n",
      "Train accuracy: 0.9102564102564102\n",
      "Test accuracy:  0.9487179487179487\n",
      "\n",
      "CPU times: total: 3.64 s\n",
      "Wall time: 469 ms\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>vc2c</th>\n",
       "      <th>vc3c</th>\n",
       "      <th>wf24f</th>\n",
       "      <th>wf4f</th>\n",
       "      <th>wf2f</th>\n",
       "      <th>pk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.814516</td>\n",
       "      <td>0.648258</td>\n",
       "      <td>0.723419</td>\n",
       "      <td>0.724794</td>\n",
       "      <td>0.910256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.842742</td>\n",
       "      <td>0.798387</td>\n",
       "      <td>0.628781</td>\n",
       "      <td>0.728460</td>\n",
       "      <td>0.725940</td>\n",
       "      <td>0.903846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.846774</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.645509</td>\n",
       "      <td>0.726169</td>\n",
       "      <td>0.721815</td>\n",
       "      <td>0.916667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.850806</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.640238</td>\n",
       "      <td>0.727773</td>\n",
       "      <td>0.724794</td>\n",
       "      <td>0.910256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.826613</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.642530</td>\n",
       "      <td>0.722273</td>\n",
       "      <td>0.721815</td>\n",
       "      <td>0.910256</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       vc2c      vc3c     wf24f      wf4f      wf2f        pk\n",
       "0  0.838710  0.814516  0.648258  0.723419  0.724794  0.910256\n",
       "1  0.842742  0.798387  0.628781  0.728460  0.725940  0.903846\n",
       "2  0.846774  0.774194  0.645509  0.726169  0.721815  0.916667\n",
       "3  0.850806  0.774194  0.640238  0.727773  0.724794  0.910256\n",
       "4  0.826613  0.774194  0.642530  0.722273  0.721815  0.910256"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# Applying Global Ordinary Least Squares\n",
    "header = [dataset_name for dataset_name in datasets.keys()]\n",
    "results = np.zeros((n_init, len(header)))\n",
    "\n",
    "count=0 # counting datasets\n",
    "for dataset_name in datasets:\n",
    "    X = datasets[dataset_name]['features'].values\n",
    "    y = datasets[dataset_name]['labels'].values\n",
    "    \n",
    "    acc = [0]*n_init\n",
    "    for i in range(n_init):\n",
    "        acc_tr, acc_ts = run_round(X, y, test_size, LinearRegression, {})\n",
    "        acc[i] = acc_tr\n",
    "            \n",
    "    results[:,count] = acc\n",
    "    count+=1\n",
    "    \n",
    "results_gols = pd.DataFrame(results, columns=header)\n",
    "results_gols.head()\n",
    "# Wall time: 3.21 s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Local model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting 'vc2c' at 2022-08-15 12:07:00.110313\n",
      "ks = [  2 198]\n",
      "2\n",
      "198\n",
      "vc2c done!\n",
      " \n",
      "Starting 'vc3c' at 2022-08-15 12:07:01.765312\n",
      "ks = [  2 198]\n",
      "2\n",
      "198\n",
      "vc3c done!\n",
      " \n",
      "Starting 'wf24f' at 2022-08-15 12:07:03.461310\n",
      "ks = [   2 3491]\n",
      "2\n",
      "3491\n",
      "wf24f done!\n",
      " \n",
      "Starting 'wf4f' at 2022-08-15 12:09:14.614312\n",
      "ks = [   2 3491]\n",
      "2\n",
      "3491\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[1;32m<timed exec>:34\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n",
      "File \u001b[1;32mD:\\Portfolio\\Research\\regional-classifiers\\devcode\\models\\local_learning.py:40\u001b[0m, in \u001b[0;36mLocalModel.fit\u001b[1;34m(self, X, Y, Cluster_params, verboses)\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m Cluster_params:\n\u001b[0;32m     38\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mClusterAlg \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mClusterAlg(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mCluster_params)\n\u001b[1;32m---> 40\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mClusterAlg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     41\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclusters \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mClusterAlg\u001b[38;5;241m.\u001b[39mcluster_centers_\n\u001b[0;32m     43\u001b[0m \u001b[38;5;66;03m# Local models training\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1179\u001b[0m, in \u001b[0;36mKMeans.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m   1175\u001b[0m best_inertia, best_labels \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1177\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_init):\n\u001b[0;32m   1178\u001b[0m     \u001b[38;5;66;03m# Initialize centers\u001b[39;00m\n\u001b[1;32m-> 1179\u001b[0m     centers_init \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_init_centroids\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1180\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_squared_norms\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx_squared_norms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minit\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrandom_state\u001b[49m\n\u001b[0;32m   1181\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1182\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose:\n\u001b[0;32m   1183\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInitialization complete\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1090\u001b[0m, in \u001b[0;36mKMeans._init_centroids\u001b[1;34m(self, X, x_squared_norms, init, random_state, init_size)\u001b[0m\n\u001b[0;32m   1087\u001b[0m     n_samples \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m   1089\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(init, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m init \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mk-means++\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m-> 1090\u001b[0m     centers, _ \u001b[38;5;241m=\u001b[39m \u001b[43m_kmeans_plusplus\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1091\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1092\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_clusters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1093\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrandom_state\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1094\u001b[0m \u001b[43m        \u001b[49m\u001b[43mx_squared_norms\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx_squared_norms\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1095\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1096\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(init, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m init \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrandom\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m   1097\u001b[0m     seeds \u001b[38;5;241m=\u001b[39m random_state\u001b[38;5;241m.\u001b[39mpermutation(n_samples)[:n_clusters]\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:223\u001b[0m, in \u001b[0;36m_kmeans_plusplus\u001b[1;34m(X, n_clusters, x_squared_norms, random_state, n_local_trials)\u001b[0m\n\u001b[0;32m    218\u001b[0m distance_to_candidates \u001b[38;5;241m=\u001b[39m _euclidean_distances(\n\u001b[0;32m    219\u001b[0m     X[candidate_ids], X, Y_norm_squared\u001b[38;5;241m=\u001b[39mx_squared_norms, squared\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    220\u001b[0m )\n\u001b[0;32m    222\u001b[0m \u001b[38;5;66;03m# update closest distances squared and potential for each candidate\u001b[39;00m\n\u001b[1;32m--> 223\u001b[0m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mminimum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclosest_dist_sq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdistance_to_candidates\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdistance_to_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    224\u001b[0m candidates_pot \u001b[38;5;241m=\u001b[39m distance_to_candidates\u001b[38;5;241m.\u001b[39msum(axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m    226\u001b[0m \u001b[38;5;66;03m# Decide which candidate is the best\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import datetime\n",
    "\n",
    "# Applying Local Ordinary Least Squares\n",
    "\n",
    "n_ks = 2 # number of clusters to evaluate for each dataset\n",
    "# for each dataset\n",
    "for dataset_name in datasets:\n",
    "    print(\"Starting '{}' at {}\".format(dataset_name,datetime.datetime.now()))\n",
    "    \n",
    "    X = datasets[dataset_name]['features'].values\n",
    "    Y = datasets[dataset_name]['labels'].values\n",
    "    \n",
    "    max_k = int(0.8*len(X)*(1-test_size)) # k_max = 80% of the number of samples on the train set\n",
    "    ks = np.linspace(2, max_k, num=n_ks, dtype='int')\n",
    "    print(\"ks = {}\".format(ks))\n",
    "    header = [\"k={}\".format(i) for i in ks] # header with the number of clusters\n",
    "    \n",
    "    results = np.zeros((n_init, len(ks)))\n",
    "    for j in range(len(ks)): # for each value of k\n",
    "        print(ks[j])\n",
    "        for i in range(n_init): # run n_init independent train/test split and evaluation\n",
    "            # Train/Test split\n",
    "            X_train, X_test, y_train, y_test = train_test_split(X,Y,test_size=test_size)\n",
    "\n",
    "            # scaling features\n",
    "            X_tr_norm, X_ts_norm = scale_feat(X_train, X_test, scaleType=scaleType)\n",
    "    \n",
    "            # creating clustering and model algorithm\n",
    "            kmeans = KMeans(n_clusters=ks[j], n_init=10)\n",
    "            linReg = LinearRegression()\n",
    "            \n",
    "            # creating and fitting local model\n",
    "            lm = LocalModel(ClusterAlg=kmeans, ModelAlg=linReg)\n",
    "            lm.fit(X_tr_norm, y_train)\n",
    "\n",
    "            # evaluating accuracy on the test set\n",
    "            y_pred_ts = lm.predict(X_ts_norm, rounded=True)\n",
    "            cm_ts = confusion_matrix(dummie2multilabel(y_test),\n",
    "                                     dummie2multilabel(y_pred_ts))\n",
    "\n",
    "            acc_ts = cm2acc(cm_ts)\n",
    "            results[i,j] = acc_ts\n",
    "\n",
    "        \n",
    "    results_df = pd.DataFrame(results, columns=header)\n",
    "    filename   = f\"{base_path}LOLS - {dataset_name} - n_init {n_init}\"\n",
    "    results_df.to_csv(filename, sep='\\t') # saving results in CSV file\n",
    "    print(\"{} done!\".format(dataset_name))\n",
    "    print(\" \")\n",
    "    \n",
    "# CPU times: user 55min 5s, sys: 18min 22s, total: 1h 13min 28s\n",
    "# Wall time: 12h 57min 42s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Processing results:\n",
    "\n",
    "The following results are part of the experiments conducted during the development of this work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note that the 'base_path' tells you where to get the results files. \n",
    "# In this case, we are getting the files regarding our experiments.\n",
    "base_path = \"results/\"\n",
    "\n",
    "#loading results\n",
    "pk_path = f\"{base_path}LOLS - pk - n_init 100 - 2019-06-12.csv\"\n",
    "\n",
    "vc2c_path = f\"{base_path}LOLS - vc2c - n_init 100 - 2019-06-12.csv\"\n",
    "vc3c_path = f\"{base_path}LOLS - vc3c - n_init 100 - 2019-06-12.csv\"\n",
    "\n",
    "wf2f_path  = f\"{base_path}LOLS - wf2f - n_init 100 - 2019-06-12.csv\"\n",
    "wf4f_path  = f\"{base_path}LOLS - wf4f - n_init 100 - 2019-06-12.csv\"\n",
    "wf24f_path = f\"{base_path}LOLS - wf24f - n_init 100 - 2019-06-12.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'results/LOLS - pk - n_init 100 - 2019-06-12.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [34]\u001b[0m, in \u001b[0;36m<cell line: 5>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m results \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGOLS\u001b[39m\u001b[38;5;124m'\u001b[39m: {}, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLOLS\u001b[39m\u001b[38;5;124m'\u001b[39m: {}}\n\u001b[0;32m      3\u001b[0m results[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGOLS\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m results_gols\n\u001b[1;32m----> 5\u001b[0m results[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLOLS\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpk\u001b[39m\u001b[38;5;124m'\u001b[39m]   \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpk_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdelim_whitespace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m results[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLOLS\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvc2c\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(vc2c_path, delim_whitespace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m      8\u001b[0m results[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLOLS\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvc3c\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(vc3c_path, delim_whitespace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\util\\_decorators.py:311\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    305\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[0;32m    306\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    307\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39marguments),\n\u001b[0;32m    308\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[0;32m    309\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mstacklevel,\n\u001b[0;32m    310\u001b[0m     )\n\u001b[1;32m--> 311\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:680\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    665\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    666\u001b[0m     dialect,\n\u001b[0;32m    667\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    676\u001b[0m     defaults\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdelimiter\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[0;32m    677\u001b[0m )\n\u001b[0;32m    678\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 680\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:575\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    572\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    574\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 575\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    577\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    578\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:933\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    930\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m    932\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 933\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1217\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1213\u001b[0m     mode \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1214\u001b[0m \u001b[38;5;66;03m# error: No overload variant of \"get_handle\" matches argument types\u001b[39;00m\n\u001b[0;32m   1215\u001b[0m \u001b[38;5;66;03m# \"Union[str, PathLike[str], ReadCsvBuffer[bytes], ReadCsvBuffer[str]]\"\u001b[39;00m\n\u001b[0;32m   1216\u001b[0m \u001b[38;5;66;03m# , \"str\", \"bool\", \"Any\", \"Any\", \"Any\", \"Any\", \"Any\"\u001b[39;00m\n\u001b[1;32m-> 1217\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[call-overload]\u001b[39;49;00m\n\u001b[0;32m   1218\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1219\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1220\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1221\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1222\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1223\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1224\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1225\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1226\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1227\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1228\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\common.py:789\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    784\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    785\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    786\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    787\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    788\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 789\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    790\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    791\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    792\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    793\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    794\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    795\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    796\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    797\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    798\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'results/LOLS - pk - n_init 100 - 2019-06-12.csv'"
     ]
    }
   ],
   "source": [
    "results = {'GOLS': {}, 'LOLS': {}}\n",
    "\n",
    "results['GOLS'] = results_gols\n",
    "\n",
    "results['LOLS']['pk']   = pd.read_csv(pk_path, delim_whitespace=True)\n",
    "\n",
    "results['LOLS']['vc2c'] = pd.read_csv(vc2c_path, delim_whitespace=True)\n",
    "results['LOLS']['vc3c'] = pd.read_csv(vc3c_path, delim_whitespace=True)\n",
    "\n",
    "results['LOLS']['wf2f']  = pd.read_csv(wf2f_path, delim_whitespace=True)\n",
    "results['LOLS']['wf4f']  = pd.read_csv(wf4f_path, delim_whitespace=True)\n",
    "results['LOLS']['wf24f'] = pd.read_csv(wf24f_path, delim_whitespace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import plotly.offline as py\n",
    "import plotly.graph_objs as go\n",
    "\n",
    "from devcode.utils.visualization import render_boxplot\n",
    "# py.init_notebook_mode(connected=True) # enabling plot within jupyter notebook\n",
    "\n",
    "for dataset_name in datasets:\n",
    "    ks = results['LOLS'][dataset_name].columns.tolist()\n",
    "    ks.insert(0,\"k=0\")\n",
    "    \n",
    "    render_boxplot(results, dataset_name, ks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that:\n",
    "\n",
    "* In the Vertebral Column dataset we had a drop in accuracy when using local modeling, showing us that the problem is\n",
    "simple enough to be resolved with a linear classifier;\n",
    "* In the Wall-following dataset we had an improvement in accuracy, more features we had more difference we saw.\n",
    "That gives us evidence that the classification problem has a non-linear decision boundary and that local modeling had\n",
    "the ability to approximate this non-linearity by a combination of local linear classifiers;\n",
    "* In the Parkinson dataset we had a slight improvement in accuracy, showing us that local linear classifier was better\n",
    "than global linear classifier."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
